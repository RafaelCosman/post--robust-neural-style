<!doctype html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <script src="https://distill.pub/template.v2.js"></script>
  <style><%= require("raw-loader!../static/style.css") %></style>
  <style><%= require("raw-loader!../static/assets/image-picker/image-picker.css") %></style>
  <style><%= require("raw-loader!../static/assets/rnst/css/image-picker.css") %></style>
  <style><%= require("raw-loader!../static/assets/juxtapose/juxtapose.css") %></style>
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.0/jquery.min.js"></script>
  <script><%= require("raw-loader!../static/assets/image-picker/image-picker.min.js") %></script>
  <script><%= require("raw-loader!../static/assets/juxtapose/juxtapose.js") %></script>
  <script src="assets/d3.min.js"></script>
</head>

<body>

<d-front-matter>
  <script type="text/json">{
  "title": "Adversarially Robust Neural Style Transfer",
  "description": "An experiment showing adversarial robustness makes neural style transfer work on a non-VGG architecture",
  "password": "bugs",
  "authors": [
    {
      "author": "Reiichiro Nakano",
      "authorURL": "https://reiinakano.com/",
      "affiliation": "",
      "affiliationURL": ""
    }
  ],
  "katex": {
    "delimiters": [
      {
        "left": "$",
        "right": "$",
        "display": false
      },
      {
        "left": "$$",
        "right": "$$",
        "display": true
      }
    ]
  }
  }</script>
</d-front-matter>

<d-title></d-title>

<d-article>

  <p>
    A figure in Ilyas, et. al.<d-cite key="ilyas2019adversarial"></d-cite> that struck me as particularly interesting 
    was the following graph showing a correlation between adversarial transferability between architectures and their 
    tendency to learn similar non-robust features.
  </p>
  
  <figure id="figure-agent-adversarial" class="subgrid">
    <figcaption style="grid-column: kicker">
      Adversarial training of agent for reconstruction.
    </figcaption>
    <div class="l-body">
      <img src="images/transferability.png">
    </div>
  </figure>

  <p>
    One way to interpret this graph is that it shows how well a particular architecture is able to capture non-robust features in an image.
    <d-footnote>Since the non-robust features are defined by the non-robust features ResNet-50 captures, $NRF_{resnet}$, what this graph really shows is how well an architecture captures $NRF_{resnet}$.</d-footnote>
  </p>

  <p>
    Notice how far back VGG is compared to the other models.
  </p>

  <p>
    In the unrelated field of neural style transfer<d-cite key="gatys2015"></d-cite>, VGG-based<d-cite key="simonyan2014very"></d-cite> neural networks are also quite special since non-VGG architectures are known to not work very well <d-footnote>This phenomenon is discussed at length in <a href="https://www.reddit.com/r/MachineLearning/comments/7rrrk3/d_eat_your_vggtables_or_why_does_neural_style/">this Reddit thread</a>.</d-footnote> without some sort of parameterization trick <d-cite key="mordvintsev2018differentiable"></d-cite>.
    The above interpretation of the graph provides an alternative explanation for this phenomenon.
    <b>Since VGG is unable to capture non-robust features as well as other architectures, the outputs for style transfer actually look more correct to humans!</b>
    <d-footnote>To follow this argument, note that the perceptual losses used in neural style transfer are dependent on matching features learned by a separately trained image classifier. If these learned features don't make sense to humans (non-robust features), the outputs for neural style transfer won't make sense either.</d-footnote>
  </p>

  <p>
    Before proceeding, let's quickly discuss the results obtained by Mordvintsev, et. al.<d-cite key="mordvintsev2018differentiable"></d-cite> in <a href="https://distill.pub/2018/differentiable-parameterizations/">Differentiable Image Parameterizations</a>, where they show that non-VGG architectures can be used for style transfer with a simple technique previously established in feature visualization<d-cite key="olah2017feature"></d-cite>.
    In their experiment, instead of optimizing the output image in RGB space, they optimize it in Fourier space, and run the image through a series of transformations (e.g jitter, rotation, scaling) before passing it through the neural network.
  </p>

  <style>
  #style-transfer-slider.juxtapose {
    max-height: 512px;
    max-width: 512px;
  }
  </style>
  <figure class="subgrid">
    <div class="l-body">
      <b>Content image</b>
      <select id="content-select" class="image-picker">
          <option data-img-src="images/thumbnails/ben.jpg" value="ben"></option>
          <option data-img-src="images/thumbnails/dancing.jpg" value="dancing"></option>
          <option data-img-src="images/thumbnails/tubingen.jpg" value="tubingen"></option>
      </select>
      <b>Style image</b>
      <select id="style-select" class="image-picker">
          <option data-img-src="images/thumbnails/scream.jpg" value="scream"></option>
          <option data-img-src="images/thumbnails/starrynight.jpg" value="starry"></option>
          <option data-img-src="images/thumbnails/woman.jpg" value="woman"></option>
          <option data-img-src="images/thumbnails/picasso.jpg" value="picasso"></option>
      </select>
      <label><input id="check-compare-vgg" type="checkbox"><small>&nbsp; Compare VGG <> Robust ResNet</small></label>
      <div id="style-transfer-slider" class="align-center" style="padding-top: 10px;"></div>
    </div>
  </figure>
  <script><%= require("raw-loader!../static/assets/rnst/js/style-transfer-slider.js") %></script>

  <p>
    Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet.
    <d-footnote>Test! Let's cite<d-cite key="gatys2015"></d-cite> someone!</d-footnote>
    More text!
  </p> 

  <link rel="stylesheet" href="assets/rnst/css/artifacts.css">
  <div class="deepdream-examples l-body-outset">
      <figure class="example" style="margin-bottom:20px;">
        <div class="original" data-focus="10,0.43,0.21">
          <img src="images/zoom/vgg_texture.jpg">
          <div class="reticle"></div>
        </div>
        <div class="closeup">
          <img src="images/zoom/vgg_texture.jpg">
        </div>
        <figcaption>
          Texture synthesized with VGG.<br>
          <i>Mild artifacts.</i>
        </figcaption>
      </figure>
      <figure class="example" style="margin-top:20px;">
        <div class="original" data-focus="10,0.64,0.74">
          <img src="images/zoom/resnet_texture.jpg">
          <div class="reticle"></div>
        </div>
        <div class="closeup">
          <img src="images/zoom/resnet_texture.jpg">
        </div>
        <figcaption>
          Texture synthesized with robust ResNet.<br>
          <i>Severe artifacts.</i>
        </figcaption>
      </figure>
  </div>
  <figcaption style="margin-top:-20px;padding-bottom:20px;">A comparison of artifacts between textures synthesized by VGG and ResNet. Interact by hovering around the images. This diagram was repurposed from <a href="https://distill.pub/2016/deconv-checkerboard/">Deconvolution and Checkerboard Artifacts</a> by Odena, et. al.</figcaption>

  <script src="assets/rnst/js/artifacts.js"></script>

</d-article>



<d-appendix>
  <h3>Acknowledgments</h3>
  <p>
    We are deeply grateful to...
  </p>

  <p>
    Many of our diagrams are based on...
  </p>

  <h3>Author Contributions</h3>
  <p>
    <b>Research:</b> Alex developed ...
  </p>

  <p>
    <b>Writing & Diagrams:</b> The text was initially drafted by...
  </p>


  <d-footnote-list></d-footnote-list>
  <d-citation-list></d-citation-list>
</d-appendix>

<!-- bibliography will be inlined during Distill pipeline's pre-rendering -->
<d-bibliography src="bibliography.bib"></d-bibliography>

</body>
